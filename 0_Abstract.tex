
Applications that exploit the architecural details of high performance computing (HPC) systems have become increasingly invaluable in academia and industry over the past two decades.
The most important hardware development of the last decade in HPC has been the General Purpose Graphics Processing Unit (GPGPU), a class of massively parallel devices that now contributes a substantial balance of the computational power in the top 500 supercomputers.
As these systems grow small costs such as latency, the fixed cost of memory accesses, accumulate over the numerous iterations in a large simulation becoming a significant barrier to performance. 
The swept time-space decomposition rule is a communication-avoiding technique for time-stepping stencil update formulas that attempts to sidestep a portion of the latency costs.
This work extends the swept rule by targeting heterogeneous, CPU\slash GPU architectures representative of current and future HPC systems.
We compare our approach to a naive decomposition scheme with two test equations using an MPI+CUDA pattern on 40 processes over two nodes containing one GPU.
We show that the swept rule produces a \SIrange{4}{18}{$\times$} speedup with the heat equation and a \SIrange{1.5}{3}{$\times$} speedup on the Euler equations using the same processors and work distribution.
These results demonstrate the effectiveness of the swept rule for different equations and numerical schemes on compute systems that incur substantial latency costs.
